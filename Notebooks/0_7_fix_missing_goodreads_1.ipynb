{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9cafe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import string\n",
    "from time import sleep\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver import firefox\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "from tqdm.auto import tqdm\n",
    "from ratelimit import limits, sleep_and_retry\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46d1dacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23c211ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv('no_null_prosecraft.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d24bed",
   "metadata": {},
   "source": [
    "Let's do a bit of exploring! Some books were unable to be found on Goodreads on my first pass. They'll have null values for both genre and year. \n",
    "\n",
    "Some other books were found on Goodreads, as evidenced by the year showing up in the dataframe, but Goodreads did not have data on their genres. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a762afde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of the 24857 books we have data for, we were unable to find 2362 of them on goodreads on our first try (9.5%). \n",
      "In this notebook, we'll try again. \n",
      "2157 (8.7%) of the books were found, but had no listed genres. \n",
      "Since genre is our target feature, these books will have to be dropped. \n"
     ]
    }
   ],
   "source": [
    "no_goodreads_count = np.sum((books['genre'] == '[]') & books['year'].isna())\n",
    "no_genres_count = np.sum((books['genre'] == '[]') & books['year'].notna())\n",
    "print(f'''Of the {len(books)} books we have data for, we were unable to find {no_goodreads_count} of them on goodreads on our first try ({round(no_goodreads_count/len(books)*100,1)}%). \n",
    "In this notebook, we'll try again. \n",
    "{no_genres_count} ({round(no_genres_count/len(books)*100,1)}%) of the books were found, but had no listed genres. \n",
    "Since genre is our target feature, these books will have to be dropped. ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "485ccb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping books found on Goodreads with no genre\n",
    "to_drop = books[(books['genre'] == '[]') & books['year'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b95ca77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = books.merge(to_drop.drop_duplicates(), how='left',indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e737163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>total words</th>\n",
       "      <th>vividness</th>\n",
       "      <th>passive voice</th>\n",
       "      <th>all adverbs</th>\n",
       "      <th>ly-adverbs</th>\n",
       "      <th>non-ly-adverbs</th>\n",
       "      <th>genre</th>\n",
       "      <th>year</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Vanished Birds</td>\n",
       "      <td>Simon Jimenez</td>\n",
       "      <td>124205.0</td>\n",
       "      <td>55.18</td>\n",
       "      <td>6.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.58</td>\n",
       "      <td>['Science Fiction', 'Fiction', 'Fantasy', 'Que...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Price of Honor</td>\n",
       "      <td>Jonathan P. Brazee</td>\n",
       "      <td>77253.0</td>\n",
       "      <td>35.35</td>\n",
       "      <td>8.71</td>\n",
       "      <td>2.63</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1.92</td>\n",
       "      <td>['Science Fiction']</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Mathematical Murder of Innocence</td>\n",
       "      <td>Michael Carter</td>\n",
       "      <td>37688.0</td>\n",
       "      <td>24.08</td>\n",
       "      <td>8.11</td>\n",
       "      <td>4.13</td>\n",
       "      <td>1.56</td>\n",
       "      <td>2.58</td>\n",
       "      <td>[]</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Case of the Baker Street Irregulars</td>\n",
       "      <td>Anthony Boucher</td>\n",
       "      <td>80557.0</td>\n",
       "      <td>32.33</td>\n",
       "      <td>8.41</td>\n",
       "      <td>3.72</td>\n",
       "      <td>1.64</td>\n",
       "      <td>2.08</td>\n",
       "      <td>['Mystery', 'Fiction', 'Crime', 'Humor', 'Clas...</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zombie Nation</td>\n",
       "      <td>Charlie Dalton</td>\n",
       "      <td>64396.0</td>\n",
       "      <td>51.11</td>\n",
       "      <td>8.22</td>\n",
       "      <td>2.21</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.63</td>\n",
       "      <td>[]</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     title              author  total words   \n",
       "0                       The Vanished Birds       Simon Jimenez     124205.0  \\\n",
       "1                       The Price of Honor  Jonathan P. Brazee      77253.0   \n",
       "2     The Mathematical Murder of Innocence      Michael Carter      37688.0   \n",
       "3  The Case of the Baker Street Irregulars     Anthony Boucher      80557.0   \n",
       "4                            Zombie Nation      Charlie Dalton      64396.0   \n",
       "\n",
       "   vividness  passive voice  all adverbs  ly-adverbs  non-ly-adverbs   \n",
       "0      55.18           6.37         1.95        0.36            1.58  \\\n",
       "1      35.35           8.71         2.63        0.71            1.92   \n",
       "2      24.08           8.11         4.13        1.56            2.58   \n",
       "3      32.33           8.41         3.72        1.64            2.08   \n",
       "4      51.11           8.22         2.21        0.58            1.63   \n",
       "\n",
       "                                               genre    year     _merge  \n",
       "0  ['Science Fiction', 'Fiction', 'Fantasy', 'Que...  2020.0  left_only  \n",
       "1                                ['Science Fiction']  2017.0  left_only  \n",
       "2                                                 []  2020.0       both  \n",
       "3  ['Mystery', 'Fiction', 'Crime', 'Humor', 'Clas...  1940.0  left_only  \n",
       "4                                                 []  2020.0       both  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fa77e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = books[books['_merge'] == 'left_only'].drop('_merge', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3f7c9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((books['genre'] == '[]') & books['year'].notna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f956e56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_retry = books[(books['genre'] == '[]') & books['year'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ff62384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>total words</th>\n",
       "      <th>vividness</th>\n",
       "      <th>passive voice</th>\n",
       "      <th>all adverbs</th>\n",
       "      <th>ly-adverbs</th>\n",
       "      <th>non-ly-adverbs</th>\n",
       "      <th>genre</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The Teacher</td>\n",
       "      <td>Michael Ben-Naftali</td>\n",
       "      <td>50233.0</td>\n",
       "      <td>37.06</td>\n",
       "      <td>7.20</td>\n",
       "      <td>2.93</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.68</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Ryan's Christmas</td>\n",
       "      <td>L. J. Ross</td>\n",
       "      <td>41547.0</td>\n",
       "      <td>41.47</td>\n",
       "      <td>8.49</td>\n",
       "      <td>2.84</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.91</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>The Very Best of Caitlin R. Kiernan</td>\n",
       "      <td>Caitlin R. Kiernan</td>\n",
       "      <td>165604.0</td>\n",
       "      <td>62.20</td>\n",
       "      <td>7.67</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.90</td>\n",
       "      <td>2.30</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Christmas Pig</td>\n",
       "      <td>J. K. Rowling</td>\n",
       "      <td>51218.0</td>\n",
       "      <td>61.10</td>\n",
       "      <td>7.93</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.81</td>\n",
       "      <td>2.36</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Fatal Love</td>\n",
       "      <td>Michael Patterson</td>\n",
       "      <td>85334.0</td>\n",
       "      <td>18.00</td>\n",
       "      <td>11.14</td>\n",
       "      <td>5.15</td>\n",
       "      <td>2.14</td>\n",
       "      <td>3.01</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  title               author  total words   \n",
       "19                          The Teacher  Michael Ben-Naftali      50233.0  \\\n",
       "20                     Ryan's Christmas           L. J. Ross      41547.0   \n",
       "53  The Very Best of Caitlin R. Kiernan   Caitlin R. Kiernan     165604.0   \n",
       "55                        Christmas Pig        J. K. Rowling      51218.0   \n",
       "63                           Fatal Love    Michael Patterson      85334.0   \n",
       "\n",
       "    vividness  passive voice  all adverbs  ly-adverbs  non-ly-adverbs genre   \n",
       "19      37.06           7.20         2.93        1.25            1.68    []  \\\n",
       "20      41.47           8.49         2.84        0.94            1.91    []   \n",
       "53      62.20           7.67         3.20        0.90            2.30    []   \n",
       "55      61.10           7.93         3.17        0.81            2.36    []   \n",
       "63      18.00          11.14         5.15        2.14            3.01    []   \n",
       "\n",
       "    year  \n",
       "19   NaN  \n",
       "20   NaN  \n",
       "53   NaN  \n",
       "55   NaN  \n",
       "63   NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_retry.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b103f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2362"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(to_retry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d18653a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill in my Goodreads username and password from the .env\n",
    "user_name = os.environ.get('USER')\n",
    "password = os.environ.get('PASSWORD')\n",
    "\n",
    "#This is just the URL I get when I go to goodreads and select log in by email.\n",
    "login_url = os.environ.get('URL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c7a6dd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here I start up a headless Firefox browser through Selenium\n",
    "s = Service(\"geckodriver.exe\")\n",
    "opts=Options()\n",
    "opts.add_argument('-headless')\n",
    "browser = webdriver.Firefox(service=s)\n",
    "browser.get(login_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7559ff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I log into goodreads\n",
    "log_email = browser.find_element(By.ID, value=\"ap_email\")\n",
    "log_pwd = browser.find_element(By.ID, value=\"ap_password\")\n",
    "log_email.send_keys(user_name)\n",
    "log_pwd.send_keys(password)\n",
    "log_pwd.submit()\n",
    "sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5257333",
   "metadata": {},
   "source": [
    "The get_genres_legacy() function was my first, somewhat involved attempt to find books the original function had missed. It improved upon the original function by not giving up after the first page of results, checking the second and third pages too. However, I later discovered that searching both the title and author at once has a much higher success rate, much faster. \n",
    "\n",
    "Of the first 5 books I tried, the legacy function managed to find one of them in about 5 minutes.\n",
    "\n",
    "The new, simpler function managed to find 4 of them, in less than a minute and a half."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2cc200e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genres_legacy(title, author):\n",
    "    '''Replaced by a much simpler get_genres, this function searches the first three pages\n",
    "    of title results and, if unsuccessful, searches the first three pages of author results.'''\n",
    "    book_id = -1\n",
    "    itemqueue = []\n",
    "    trials = 0\n",
    "    page = 1\n",
    "    \n",
    "    #Put the title into the search bar\n",
    "    while (len(itemqueue) == 0) and (trials < 3):\n",
    "        browser.get('http://www.goodreads.com/search?q=&qid=')\n",
    "        search_book = browser.find_element(By.ID, value='search_query_main')\n",
    "        search_book.send_keys(title)\n",
    "        search_book.submit()\n",
    "        sleep(random.uniform(3,10))\n",
    "        itemqueue = browser.find_elements(By.XPATH, value=\"//table/tbody/tr[contains(@itemtype, 'http://schema.org/Book')]\")\n",
    "        img = browser.find_elements(By.CLASS_NAME, value=\"bookCover\")\n",
    "        book_list = list()\n",
    "        trials += 1\n",
    "    \n",
    "    #Search the first page of results for the author's name\n",
    "    #Use only first author if multiple\n",
    "     \n",
    "    for i in range(len(itemqueue)):\n",
    "        book_list.append(itemqueue[i].text.split('\\n'))\n",
    "        book_list_ap = list()\n",
    "    for i in range(0, len(book_list)):\n",
    "         book_list_ap.append((book_list[i][0],book_list[i][1],img[i].get_property(\"src\")))\n",
    "    for book in book_list_ap:\n",
    "        if f\"by {author.split(' &')[0]}\" in book[1]:\n",
    "            book_id = book[2].split('/')[-1].split('.')[0]\n",
    "            break\n",
    "    \n",
    "    #Now let's check the second and third page of results. \n",
    "    if book_id == -1:\n",
    "        for j in range(2):\n",
    "            sleep(random.uniform(3,10))\n",
    "            book_list = list()\n",
    "            try: \n",
    "                nextpage = browser.find_element(By.CLASS_NAME, value=\"next_page\")\n",
    "            except NoSuchElementException: \n",
    "                year = np.nan\n",
    "                break\n",
    "            nextpage.click()\n",
    "            itemqueue = browser.find_elements(By.XPATH, value=\"//table/tbody/tr[contains(@itemtype, 'http://schema.org/Book')]\")\n",
    "            img = browser.find_elements(By.CLASS_NAME, value=\"bookCover\")\n",
    "            \n",
    "            for i in range(len(itemqueue)):\n",
    "                book_list.append(itemqueue[i].text.split('\\n'))\n",
    "                book_list_ap = list()\n",
    "            for i in range(0, len(book_list)):\n",
    "                book_list_ap.append((book_list[i][0],book_list[i][1],img[i].get_property(\"src\")))\n",
    "            for book in book_list_ap:\n",
    "                if f\"by {author.split(' &')[0]}\" in book[1]:\n",
    "                    book_id = book[2].split('/')[-1].split('.')[0]\n",
    "                    break\n",
    "            sleep(random.uniform(3,10))\n",
    "            \n",
    "        \n",
    "        \n",
    "            \n",
    "    #Sometimes, a book's title is so common that the correct version isn't on the three pages\n",
    "    #If that happens, try putting the author into the search bar\n",
    "    #And searching the first page for the correct title\n",
    "    \n",
    "    if book_id == -1:\n",
    "        browser.get('http://www.goodreads.com/search?q=&qid=')\n",
    "        search_book = browser.find_element(By.ID, value='search_query_main')\n",
    "        search_book.send_keys(author)\n",
    "        search_book.submit()\n",
    "        sleep(random.uniform(3,10))\n",
    "        itemqueue = browser.find_elements(By.XPATH, value=\"//table/tbody/tr[contains(@itemtype, 'http://schema.org/Book')]\")\n",
    "        img = browser.find_elements(By.CLASS_NAME, value=\"bookCover\")\n",
    "        book_list = list()\n",
    "        for i in range(len(itemqueue)):\n",
    "            book_list.append(itemqueue[i].text.split('\\n'))\n",
    "            book_list_ap = list()\n",
    "        for i in range(0, len(book_list)):\n",
    "             book_list_ap.append((book_list[i][0],book_list[i][1],img[i].get_property(\"src\")))\n",
    "        for book in book_list_ap:\n",
    "            if title in book[0]:\n",
    "                book_id = book[2].split('/')[-1].split('.')[0]\n",
    "                break\n",
    "    \n",
    "    #If that doesn't work, check the second and third author page.\n",
    "    \n",
    "    if book_id == -1:\n",
    "        for j in range(2):\n",
    "            sleep(random.uniform(3,10))\n",
    "            try: \n",
    "                nextpage = browser.find_element(By.CLASS_NAME, value=\"next_page\")\n",
    "            except NoSuchElementException:\n",
    "                year = np.nan\n",
    "                break\n",
    "            nextpage.click()\n",
    "            itemqueue = browser.find_elements(By.XPATH, value=\"//table/tbody/tr[contains(@itemtype, 'http://schema.org/Book')]\")\n",
    "            img = browser.find_elements(By.CLASS_NAME, value=\"bookCover\")\n",
    "            book_list = list()\n",
    "            for i in range(len(itemqueue)):\n",
    "                book_list.append(itemqueue[i].text.split('\\n'))\n",
    "                book_list_ap = list()\n",
    "            for i in range(0, len(book_list)):\n",
    "                book_list_ap.append((book_list[i][0],book_list[i][1],img[i].get_property(\"src\")))\n",
    "            for book in book_list_ap:\n",
    "                if title in book[0]:\n",
    "                    book_id = book[2].split('/')[-1].split('.')[0]\n",
    "                    break\n",
    "        \n",
    "    if book_id == -1:\n",
    "        return ([], np.nan)\n",
    "    book_url = f'https://www.goodreads.com/book/show/{book_id}'\n",
    "    browser.get(book_url)\n",
    "    genres = browser.find_elements(By.XPATH, value=\"//span[contains(@class, 'BookPageMetadataSection__genreButton')]\")\n",
    "    try: \n",
    "        datestring = browser.find_element(By.CSS_SELECTOR, \".FeaturedDetails > p:nth-child(2)\")\n",
    "        year = int(datestring.text[-4:])\n",
    "    except NoSuchElementException:\n",
    "        year = np.nan\n",
    "    except ValueError:\n",
    "        year = np.nan\n",
    "    sleep(random.uniform(3,10))\n",
    "    return ([genre.text for genre in genres], year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "775e1e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "@sleep_and_retry\n",
    "def get_genres(index):\n",
    "    book_id = -1\n",
    "    itemqueue = []\n",
    "    trials = 0\n",
    "    page = 1\n",
    "    row = books.loc[index].copy()\n",
    "    title = row['title']\n",
    "    author = row['author'].replace(' & ', ' ')\n",
    "    \n",
    "    #Put the title into the search bar\n",
    "    while (len(itemqueue) == 0) and (trials < 3):\n",
    "        browser.get('http://www.goodreads.com/search?q=&qid=')\n",
    "        try: \n",
    "            search_book = browser.find_element(By.ID, value='search_query_main')\n",
    "        except NoSuchElementException: \n",
    "            sleep(random.uniform(3,10))\n",
    "            browser.get('http://www.goodreads.com/search?q=&qid=')\n",
    "            search_book = browser.find_element(By.ID, value='search_query_main')\n",
    "        search_book.send_keys(title + ' ' + author)\n",
    "        search_book.submit()\n",
    "        sleep(random.uniform(3,10))\n",
    "        itemqueue = browser.find_elements(By.XPATH, value=\"//table/tbody/tr[contains(@itemtype, 'http://schema.org/Book')]\")\n",
    "        img = browser.find_elements(By.CLASS_NAME, value=\"bookCover\")\n",
    "        book_list = list()\n",
    "        trials += 1\n",
    "        \n",
    "    #Sometimes middle initials mess up the search. Try again with just first and last name.       \n",
    "    if(len(itemqueue) == 0): \n",
    "        browser.get('http://www.goodreads.com/search?q=&qid=')\n",
    "        author = author.split()[0] + ' ' + author.split()[-1]\n",
    "        try: \n",
    "            search_book = browser.find_element(By.ID, value='search_query_main')\n",
    "        except NoSuchElementException: \n",
    "            sleep(random.uniform(3,10))\n",
    "            browser.get('http://www.goodreads.com/search?q=&qid=')\n",
    "            search_book = browser.find_element(By.ID, value='search_query_main')\n",
    "        search_book.send_keys(title + ' ' + author)\n",
    "        search_book.submit()\n",
    "        sleep(random.uniform(3,10))\n",
    "        itemqueue = browser.find_elements(By.XPATH, value=\"//table/tbody/tr[contains(@itemtype, 'http://schema.org/Book')]\")\n",
    "        img = browser.find_elements(By.CLASS_NAME, value=\"bookCover\")\n",
    "        book_list = list()\n",
    "    \n",
    "    if(len(itemqueue) > 0):\n",
    "        for i in range(len(itemqueue)):\n",
    "            book_list.append(itemqueue[i].text.split('\\n'))\n",
    "            book_list_ap = list()\n",
    "        for i in range(0, len(book_list)):\n",
    "             book_list_ap.append((book_list[i][0],book_list[i][1],img[i].get_property(\"src\")))\n",
    "        for book in book_list_ap:\n",
    "            if f\"{author.split()[-1]}\" in book[1]:\n",
    "                book_id = book[2].split('/')[-1].split('.')[0]\n",
    "                break\n",
    "    \n",
    "    if book_id == -1:\n",
    "        return row\n",
    "    book_url = f'https://www.goodreads.com/book/show/{book_id}'\n",
    "    browser.get(book_url)\n",
    "    genres = browser.find_elements(By.XPATH, value=\"//span[contains(@class, 'BookPageMetadataSection__genreButton')]\")\n",
    "    try: \n",
    "        datestring = browser.find_element(By.CSS_SELECTOR, \".FeaturedDetails > p:nth-child(2)\")\n",
    "        year = int(datestring.text[-4:])\n",
    "    except NoSuchElementException:\n",
    "        year = np.nan\n",
    "    except ValueError:\n",
    "        year = np.nan\n",
    "    sleep(random.uniform(3,10))\n",
    "    row['genre'] = [genre.text for genre in genres]\n",
    "    row['year'] = year\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ea193c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [04:51<00:00, 58.28s/it]\n"
     ]
    }
   ],
   "source": [
    "test_genres_legacy = to_retry.head().progress_apply(lambda row: get_genres_legacy(row['title'], row['author']),axis=1)\n",
    "test_genres_legacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8e88d923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19                                            ([], nan)\n",
       "20    ([Mystery, Crime, Fiction, Christmas, Audioboo...\n",
       "53                                            ([], nan)\n",
       "55                                            ([], nan)\n",
       "63                                            ([], nan)\n",
       "dtype: object"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d6b377dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:23<00:00, 16.79s/it]\n"
     ]
    }
   ],
   "source": [
    "test_genres_new = to_retry.head().progress_apply(lambda row: get_genres_simple(row['title'], row['author']),axis=1)\n",
    "test_genres_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0f6690ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:28<00:00, 14.10s/it]\n"
     ]
    }
   ],
   "source": [
    "new_df = to_retry.head(2).progress_apply(lambda row: get_genres(row['title'], row['author']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "1d11d799",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = new_df.progress_apply(lambda row: get_genres(row.name), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b1337dea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "full = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acd606e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in tqdm.notebook.tqdm(range(int(len(to_retry)/30))):\n",
    "    part = to_retry.iloc[50*i:50*(i+1)].copy()\n",
    "    part = part.apply(lambda row: get_genres(row.name), axis=1)\n",
    "    full = pd.concat([full, part])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "f335ddbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = np.array_split(to_retry, 50)\n",
    "successful_splits = []\n",
    "df.progress_apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "fded8017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61316c4ef05a4293988f30065d35b927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm(range(len(successful_splits), len(splits))):\n",
    "    part = splits[i].apply(lambda row: get_genres(row.name), axis=1)\n",
    "    full = pd.concat([full, part])\n",
    "    successful_splits.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59711d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('has_goodreads.csv', 'a') as file:\n",
    "#    full.to_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d1249a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(new_df.loc[:,'genre'],new_df.loc[:,'year']) = new_df.progress_apply(lambda row: get_genres_simple(row['title'], row['author']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a4b13bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.progress_apply(lambda row: test_assignment(row.Name, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "636f807a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1978"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b4aaf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
